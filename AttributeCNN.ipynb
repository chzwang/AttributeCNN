{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "372a235a-5439-49fc-a0ad-8b516667350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d43dd4e-2ae0-419c-bf06-53f128afa596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('celeb_attr.csv', index_col=False)\n",
    "df = df.replace(-1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9e362e0-b7e7-4e15-83b3-668571b00c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebrityImageDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        img_path = f\"{self.img_dir}/{self.dataframe.iloc[idx]['Image_Name']}\"\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        labels = torch.tensor(self.dataframe.iloc[idx][1:].values.astype('float32'))\n",
    "\n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a496fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889d4783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "084014a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttributeCNN(nn.Module):\n",
    "    def __init__(self, num_classes=40):\n",
    "        super(AttributeCNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(128*16*16, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.relu3(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6f880c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device= torch.device(\"cuda\")\n",
    "\n",
    "model = AttributeCNN(num_classes=40)\n",
    "model.to(device)\n",
    "\n",
    "evaluator = nn.BCELoss()\n",
    "optimizer= optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c19e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_dataset = CelebrityImageDataset(train_df, img_dir='datasets/celeba/img_celeba/img_celeba', transform=transform)\n",
    "test_dataset = CelebrityImageDataset(test_df, img_dir='datasets/celeba/img_celeba/img_celeba', transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b833535",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loading = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "test_loading = DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30c2bb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: 100%|██████████| 5065/5065 [01:48<00:00, 46.65it/s, loss=0.32] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 0.2974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: 100%|██████████| 5065/5065 [01:47<00:00, 47.10it/s, loss=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 0.2874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: 100%|██████████| 5065/5065 [01:46<00:00, 47.73it/s, loss=0.297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 0.2795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]: 100%|██████████| 5065/5065 [01:44<00:00, 48.56it/s, loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.2724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]: 100%|██████████| 5065/5065 [01:45<00:00, 47.84it/s, loss=0.255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 0.2662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]: 100%|██████████| 5065/5065 [01:45<00:00, 47.80it/s, loss=0.268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 0.2604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]: 100%|██████████| 5065/5065 [01:44<00:00, 48.56it/s, loss=0.257]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.2554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]: 100%|██████████| 5065/5065 [01:43<00:00, 48.77it/s, loss=0.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]: 100%|██████████| 5065/5065 [01:44<00:00, 48.61it/s, loss=0.234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.2464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]: 100%|██████████| 5065/5065 [01:43<00:00, 48.80it/s, loss=0.237]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.2424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss= 0.0\n",
    "\n",
    "    loop = tqdm(train_loading, desc=f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "    for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        outputs = model(images) #forward pass\n",
    "        loss = evaluator(outputs, labels)\n",
    "        optimizer.zero_grad() #Zero Gradient\n",
    "        loss.backward() # Backprop\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss/len(train_loading)\n",
    "    print(f\"Epoch {epoch+1}, Loss {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a17d49b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttributeCNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu3): ReLU()\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc1): Linear(in_features=32768, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=40, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AttributeCNN()\n",
    "model.load_state_dict(torch.load('models/Model1.pth', weights_only=True))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe6bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]], device='cuda:0',\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Code\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "model = AttributeCNN()\n",
    "model.load_state_dict(torch.load('models/Model1.pth', weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "image = Image.open('image.jpg').convert(\"RGB\")\n",
    "\n",
    "image_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "image_tensor = image_tensor.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(image_tensor)\n",
    "\n",
    "\n",
    "    preds = (output > 0.5).int() \n",
    "\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a9d18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"models/Model1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8593ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1267/1267 [00:26<00:00, 48.60it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "all_predict = []\n",
    "all_targets = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_loading)\n",
    "    for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = (outputs > 0.5).float()\n",
    "        all_predict.append(preds.cpu())\n",
    "        all_targets.append(labels.cpu())\n",
    "    \n",
    "all_predict = torch.cat(all_predict, dim=0).numpy()\n",
    "all_targets = torch.cat(all_targets, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9135b8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': {'precision': 0.6523364485981309, 'recall': 0.2341757995974055, 'f1-score': 0.3446346280447663, 'support': 4471.0}, '1': {'precision': 0.6084782090974041, 'recall': 0.4721862871927555, 'f1-score': 0.5317377731529657, 'support': 10822.0}, '2': {'precision': 0.7814687087939953, 'recall': 0.744324219882137, 'f1-score': 0.7624443344878773, 'support': 20702.0}, '3': {'precision': 0.5866369710467706, 'recall': 0.1571974218190499, 'f1-score': 0.24795255577520475, 'support': 8378.0}, '4': {'precision': 0.6938775510204082, 'recall': 0.33663366336633666, 'f1-score': 0.4533333333333333, 'support': 909.0}, '5': {'precision': 0.7675753228120517, 'recall': 0.5130254115390762, 'f1-score': 0.6150014369192451, 'support': 6257.0}, '6': {'precision': 0.5695674830640959, 'recall': 0.11161033391197794, 'f1-score': 0.18664617486338797, 'support': 9793.0}, '7': {'precision': 0.6518501279962765, 'recall': 0.29283847360167276, 'f1-score': 0.4041263886885009, 'support': 9565.0}, '8': {'precision': 0.736805874254245, 'recall': 0.6655611980516115, 'f1-score': 0.6993738088755785, 'support': 9649.0}, '9': {'precision': 0.8291807432432432, 'recall': 0.65200066412087, 'f1-score': 0.7299934938191281, 'support': 6023.0}, '10': {'precision': 0.4198895027624309, 'recall': 0.03891449052739376, 'f1-score': 0.07122774133083412, 'support': 1953.0}, '11': {'precision': 0.6836343732895457, 'recall': 0.44264619019492024, 'f1-score': 0.5373583823318514, 'support': 8465.0}, '12': {'precision': 0.7107123436650353, 'recall': 0.2263203463203463, 'f1-score': 0.34331494615182556, 'support': 5775.0}, '13': {'precision': 0.4766355140186916, 'recall': 0.13127413127413126, 'f1-score': 0.2058526740665994, 'support': 2331.0}, '14': {'precision': 0.4713740458015267, 'recall': 0.13034300791556727, 'f1-score': 0.20421661843737082, 'support': 1895.0}, '15': {'precision': 0.8166666666666667, 'recall': 0.47333848531684697, 'f1-score': 0.5993150684931506, 'support': 2588.0}, '16': {'precision': 0.6323268206039077, 'recall': 0.2807570977917981, 'f1-score': 0.3888585472419443, 'support': 2536.0}, '17': {'precision': 0.7215909090909091, 'recall': 0.44405594405594406, 'f1-score': 0.5497835497835498, 'support': 1716.0}, '18': {'precision': 0.8297065282491515, 'recall': 0.7948489098559225, 'f1-score': 0.8119037541106372, 'support': 15686.0}, '19': {'precision': 0.8097588404348369, 'recall': 0.7037901824500434, 'f1-score': 0.7530649003544245, 'support': 18416.0}, '20': {'precision': 0.8884429709765602, 'recall': 0.906904945674761, 'f1-score': 0.897579033964038, 'support': 16843.0}, '21': {'precision': 0.815895597625182, 'recall': 0.7365626738130151, 'f1-score': 0.7742021205920651, 'support': 19777.0}, '22': {'precision': 0.415, 'recall': 0.049760191846522785, 'f1-score': 0.08886509635974305, 'support': 1668.0}, '23': {'precision': 0.2857142857142857, 'recall': 0.0004278990158322636, 'f1-score': 0.0008545182653279214, 'support': 4674.0}, '24': {'precision': 0.924149855907781, 'recall': 0.9464333146415607, 'f1-score': 0.9351588586092764, 'support': 33883.0}, '25': {'precision': 0.6500683994528044, 'recall': 0.20372116951041755, 'f1-score': 0.3102232667450059, 'support': 11663.0}, '26': {'precision': 0.6653386454183267, 'recall': 0.0983510011778563, 'f1-score': 0.17136993329912775, 'support': 1698.0}, '27': {'precision': 0.5663924794359577, 'recall': 0.17048368556017332, 'f1-score': 0.2620811527220825, 'support': 11309.0}, '28': {'precision': 0.6079632465543645, 'recall': 0.12340690083929126, 'f1-score': 0.20516795865633075, 'support': 3217.0}, '29': {'precision': 0.602829162132753, 'recall': 0.2046545991872922, 'f1-score': 0.3055708769994484, 'support': 2707.0}, '30': {'precision': 0.6794625719769674, 'recall': 0.3110720562390158, 'f1-score': 0.4267631103074141, 'support': 2276.0}, '31': {'precision': 0.8455479052398179, 'recall': 0.740545789043336, 'f1-score': 0.7895711872718356, 'support': 19568.0}, '32': {'precision': 0.5391367959034382, 'recall': 0.08758169934640522, 'f1-score': 0.1506849315068493, 'support': 8415.0}, '33': {'precision': 0.6820095425203481, 'recall': 0.5622397038408145, 'f1-score': 0.6163601775523145, 'support': 12966.0}, '34': {'precision': 0.6299411269974768, 'recall': 0.2894872455552693, 'f1-score': 0.39668108394386087, 'support': 7762.0}, '35': {'precision': 0.8408851422550052, 'recall': 0.3997995991983968, 'f1-score': 0.5419354838709678, 'support': 1996.0}, '36': {'precision': 0.8804261828155493, 'recall': 0.8712354507020199, 'f1-score': 0.8758067054934676, 'support': 19159.0}, '37': {'precision': 0.5172413793103449, 'recall': 0.0272892662219527, 'f1-score': 0.05184331797235023, 'support': 4947.0}, '38': {'precision': 0.7685069008782937, 'recall': 0.4148323738570945, 'f1-score': 0.5388168022872224, 'support': 2953.0}, '39': {'precision': 0.8510443752321628, 'recall': 0.9516871165644172, 'f1-score': 0.8985564086705987, 'support': 31296.0}, 'micro avg': {'precision': 0.8027750726663148, 'recall': 0.5889633958446389, 'f1-score': 0.6794453751110902, 'support': 366707.0}, 'macro avg': {'precision': 0.6776517387714186, 'recall': 0.3985579735155313, 'f1-score': 0.4669558033837875, 'support': 366707.0}, 'weighted avg': {'precision': 0.7500758549076455, 'recall': 0.5889633958446389, 'f1-score': 0.6301908169886923, 'support': 366707.0}, 'samples avg': {'precision': 0.7954224163637271, 'recall': 0.5766228009007728, 'f1-score': 0.6452075016716592, 'support': 366707.0}}\n"
     ]
    }
   ],
   "source": [
    "report=classification_report(all_targets, all_predict, output_dict=True)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "67420008",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = pd.DataFrame(report).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "115ee642",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_stats = classification_df[:-4].set_index(df.columns[1:])\n",
    "summary_stats = classification_df.iloc[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "726efebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_stats.to_csv(\"individual_stats1.csv\")\n",
    "summary_stats.to_csv(\"summary_stats1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2981cb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Image_Name             000001.jpg000002.jpg000003.jpg000004.jpg000005...\n",
       "5_o_Clock_Shadow                                                   22516\n",
       "Arched_Eyebrows                                                    54090\n",
       "Attractive                                                        103833\n",
       "Bags_Under_Eyes                                                    41446\n",
       "Bald                                                                4547\n",
       "Bangs                                                              30709\n",
       "Big_Lips                                                           48785\n",
       "Big_Nose                                                           47516\n",
       "Black_Hair                                                         48472\n",
       "Blond_Hair                                                         29983\n",
       "Blurry                                                             10312\n",
       "Brown_Hair                                                         41572\n",
       "Bushy_Eyebrows                                                     28803\n",
       "Chubby                                                             11663\n",
       "Double_Chin                                                         9459\n",
       "Eyeglasses                                                         13193\n",
       "Goatee                                                             12716\n",
       "Gray_Hair                                                           8499\n",
       "Heavy_Makeup                                                       78390\n",
       "High_Cheekbones                                                    92189\n",
       "Male                                                               84434\n",
       "Mouth_Slightly_Open                                                97942\n",
       "Mustache                                                            8417\n",
       "Narrow_Eyes                                                        23329\n",
       "No_Beard                                                          169158\n",
       "Oval_Face                                                          57567\n",
       "Pale_Skin                                                           8701\n",
       "Pointy_Nose                                                        56210\n",
       "Receding_Hairline                                                  16163\n",
       "Rosy_Cheeks                                                        13315\n",
       "Sideburns                                                          11449\n",
       "Smiling                                                            97669\n",
       "Straight_Hair                                                      42222\n",
       "Wavy_Hair                                                          64744\n",
       "Wearing_Earrings                                                   38276\n",
       "Wearing_Hat                                                         9818\n",
       "Wearing_Lipstick                                                   95715\n",
       "Wearing_Necklace                                                   24913\n",
       "Wearing_Necktie                                                    14732\n",
       "Young                                                             156734\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "64f8689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_counts = df.iloc[:, 1:].sum(axis=0).values\n",
    "negative_counts = len(df) - positive_counts\n",
    "\n",
    "pos_weight = negative_counts / (positive_counts + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "43365fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight_tensor = torch.tensor(pos_weight, dtype=torch.float32).to(device)\n",
    "evaluator = nn.BCEWithLogitsLoss(pos_weight=pos_weight_tensor)\n",
    "optimizer= optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a1b46874",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/10]: 100%|██████████| 5065/5065 [02:05<00:00, 40.34it/s, loss=0.938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 0.9074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/10]: 100%|██████████| 5065/5065 [01:46<00:00, 47.61it/s, loss=0.903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss 0.9041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/10]: 100%|██████████| 5065/5065 [01:44<00:00, 48.35it/s, loss=0.923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss 0.9041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/10]: 100%|██████████| 5065/5065 [01:43<00:00, 48.93it/s, loss=0.923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss 0.9046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5/10]: 100%|██████████| 5065/5065 [01:43<00:00, 48.81it/s, loss=0.93] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss 0.9058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6/10]: 100%|██████████| 5065/5065 [01:43<00:00, 48.73it/s, loss=1.01] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss 0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7/10]: 100%|██████████| 5065/5065 [01:43<00:00, 48.94it/s, loss=0.882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss 0.9100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8/10]: 100%|██████████| 5065/5065 [01:43<00:00, 48.78it/s, loss=0.974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss 0.9130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9/10]: 100%|██████████| 5065/5065 [01:43<00:00, 48.80it/s, loss=0.897]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss 0.9155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10/10]: 100%|██████████| 5065/5065 [01:43<00:00, 48.88it/s, loss=0.927]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss 0.9178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss= 0.0\n",
    "\n",
    "    loop = tqdm(train_loading, desc=f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "    for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        outputs = model(images) #forward pass\n",
    "        loss = evaluator(outputs, labels)\n",
    "        optimizer.zero_grad() #Zero Gradient\n",
    "        loss.backward() # Backprop\n",
    "\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    avg_loss = total_loss/len(train_loading)\n",
    "    print(f\"Epoch {epoch+1}, Loss {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5b7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1267/1267 [00:30<00:00, 42.01it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "all_predict = []\n",
    "all_targets = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_loading)\n",
    "    for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        outputs = model(images)\n",
    "        preds = (outputs > 0.5).float()\n",
    "        all_predict.append(preds.cpu())\n",
    "        all_targets.append(labels.cpu())\n",
    "    \n",
    "all_predict = torch.cat(all_predict, dim=0).numpy()\n",
    "all_targets = torch.cat(all_targets, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6465d1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.68      0.47      4471\n",
      "           1       0.53      0.66      0.59     10822\n",
      "           2       0.82      0.58      0.68     20702\n",
      "           3       0.48      0.41      0.44      8378\n",
      "           4       0.16      0.86      0.27       909\n",
      "           5       0.62      0.55      0.58      6257\n",
      "           6       0.41      0.35      0.38      9793\n",
      "           7       0.53      0.47      0.50      9565\n",
      "           8       0.60      0.77      0.67      9649\n",
      "           9       0.65      0.81      0.72      6023\n",
      "          10       0.15      0.58      0.24      1953\n",
      "          11       0.66      0.50      0.57      8465\n",
      "          12       0.47      0.52      0.49      5775\n",
      "          13       0.23      0.66      0.34      2331\n",
      "          14       0.21      0.65      0.32      1895\n",
      "          15       0.32      0.77      0.45      2588\n",
      "          16       0.32      0.72      0.45      2536\n",
      "          17       0.27      0.87      0.41      1716\n",
      "          18       0.82      0.78      0.80     15686\n",
      "          19       0.88      0.50      0.64     18416\n",
      "          20       0.88      0.86      0.87     16843\n",
      "          21       0.94      0.47      0.63     19777\n",
      "          22       0.18      0.69      0.28      1668\n",
      "          23       0.25      0.23      0.24      4674\n",
      "          24       0.97      0.74      0.84     33883\n",
      "          25       0.56      0.37      0.45     11663\n",
      "          26       0.18      0.73      0.28      1698\n",
      "          27       0.46      0.44      0.45     11309\n",
      "          28       0.25      0.69      0.37      3217\n",
      "          29       0.34      0.70      0.46      2707\n",
      "          30       0.32      0.69      0.43      2276\n",
      "          31       0.93      0.51      0.66     19568\n",
      "          32       0.35      0.49      0.41      8415\n",
      "          33       0.74      0.36      0.48     12966\n",
      "          34       0.48      0.54      0.51      7762\n",
      "          35       0.35      0.77      0.48      1996\n",
      "          36       0.89      0.80      0.84     19159\n",
      "          37       0.29      0.40      0.33      4947\n",
      "          38       0.34      0.86      0.49      2953\n",
      "          39       0.92      0.64      0.76     31296\n",
      "\n",
      "   micro avg       0.59      0.60      0.60    366707\n",
      "   macro avg       0.50      0.62      0.51    366707\n",
      "weighted avg       0.70      0.60      0.62    366707\n",
      " samples avg       0.58      0.58      0.55    366707\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skrubstar/Datahacks/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "report=classification_report(all_targets, all_predict, output_dict=False)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9284bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1267/1267 [00:25<00:00, 48.92it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "all_probabilities = []\n",
    "all_targets = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_loading)\n",
    "    for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "\n",
    "        all_probabilities.append(probabilities.cpu())\n",
    "        all_targets.append(labels.cpu())\n",
    "    \n",
    "all_predict = torch.cat(all_probabilities, dim=0).numpy()\n",
    "all_targets = torch.cat(all_targets, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "128e7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_optimal_thresholds(y_true, y_probs):\n",
    "    thresholds = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        precision, recall, threshold = precision_recall_curve(y_true[:, i], y_probs[:, i])\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "        if len(threshold) == 0:\n",
    "            thresholds.append(0.5)\n",
    "        else:\n",
    "            best_thresh = threshold[np.argmax(f1)]\n",
    "            thresholds.append(best_thresh)\n",
    "    return np.array(thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b9fcd1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_thresholds = compute_optimal_thresholds(all_targets, all_predict) #Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1fd69987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7103994 , 0.5317982 , 0.50000083, 0.5031747 , 0.73105854,\n",
       "       0.5670702 , 0.5000152 , 0.50071186, 0.5612252 , 0.71674156,\n",
       "       0.7225935 , 0.5008443 , 0.6052067 , 0.73105836, 0.7310523 ,\n",
       "       0.73105854, 0.7310584 , 0.73105854, 0.513892  , 0.50000197,\n",
       "       0.536272  , 0.50000024, 0.7310581 , 0.50038797, 0.50000006,\n",
       "       0.5000585 , 0.72613126, 0.5002488 , 0.7310583 , 0.73105556,\n",
       "       0.7310584 , 0.50000167, 0.51433396, 0.50000674, 0.5354066 ,\n",
       "       0.7310583 , 0.5024743 , 0.5459233 , 0.73105854, 0.50000006],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "79b5f266",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1267/1267 [00:25<00:00, 49.74it/s]\n"
     ]
    }
   ],
   "source": [
    "all_predict = []\n",
    "all_targets = []\n",
    "model.eval()\n",
    "\n",
    "thresholds = torch.tensor(optimal_thresholds).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_loading)\n",
    "    for images, labels in loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device).float()\n",
    "\n",
    "        outputs = model(images)\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "\n",
    "        predictions = (probabilities > thresholds.unsqueeze(0)).float()\n",
    "\n",
    "        all_predict.append(predictions.cpu())\n",
    "        all_targets.append(labels.cpu())\n",
    "    \n",
    "all_predict = torch.cat(all_predict, dim=0).numpy()\n",
    "all_targets = torch.cat(all_targets, dim=0).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6e2e6b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.63      0.48      4471\n",
      "           1       0.51      0.71      0.59     10822\n",
      "           2       0.69      0.84      0.76     20702\n",
      "           3       0.41      0.54      0.47      8378\n",
      "           4       0.00      0.00      0.00       909\n",
      "           5       0.60      0.58      0.59      6257\n",
      "           6       0.33      0.72      0.45      9793\n",
      "           7       0.45      0.62      0.52      9565\n",
      "           8       0.58      0.79      0.67      9649\n",
      "           9       0.69      0.78      0.73      6023\n",
      "          10       0.18      0.48      0.26      1953\n",
      "          11       0.54      0.64      0.59      8465\n",
      "          12       0.46      0.53      0.49      5775\n",
      "          13       0.31      0.47      0.38      2331\n",
      "          14       0.27      0.52      0.36      1895\n",
      "          15       0.00      0.00      0.00      2588\n",
      "          16       0.50      0.53      0.51      2536\n",
      "          17       0.00      0.00      0.00      1716\n",
      "          18       0.79      0.83      0.81     15686\n",
      "          19       0.67      0.73      0.70     18416\n",
      "          20       0.85      0.89      0.87     16843\n",
      "          21       0.66      0.79      0.72     19777\n",
      "          22       0.26      0.47      0.34      1668\n",
      "          23       0.18      0.51      0.27      4674\n",
      "          24       0.93      0.90      0.92     33883\n",
      "          25       0.43      0.61      0.50     11663\n",
      "          26       0.19      0.60      0.29      1698\n",
      "          27       0.39      0.68      0.49     11309\n",
      "          28       0.37      0.50      0.42      3217\n",
      "          29       0.40      0.60      0.48      2707\n",
      "          30       0.51      0.50      0.51      2276\n",
      "          31       0.71      0.74      0.73     19568\n",
      "          32       0.32      0.60      0.42      8415\n",
      "          33       0.52      0.67      0.59     12966\n",
      "          34       0.46      0.59      0.51      7762\n",
      "          35       0.64      0.57      0.60      1996\n",
      "          36       0.84      0.87      0.86     19159\n",
      "          37       0.27      0.45      0.34      4947\n",
      "          38       0.00      0.00      0.00      2953\n",
      "          39       0.86      0.90      0.88     31296\n",
      "\n",
      "   micro avg       0.59      0.73      0.65    366707\n",
      "   macro avg       0.45      0.58      0.50    366707\n",
      "weighted avg       0.62      0.73      0.66    366707\n",
      " samples avg       0.58      0.71      0.62    366707\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skrubstar/Datahacks/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "report=classification_report(all_targets, all_predict, output_dict=False)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0969e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Datahacks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
